{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "effddfc8-1018-47c4-9b16-02a320425184",
   "metadata": {},
   "source": [
    "## Initial codebase for implementing 1D convolutional network on mouse wake+sleep spiking data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd242ff",
   "metadata": {},
   "source": [
    "## To-do:\n",
    "1. dataset\n",
    "2. dataloader\n",
    "3. 1d-conv\n",
    "4. Analysis: attributions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "960a4f7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'torch.device' has no attribute 'is_cuda_available'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgenerate_binned_data\u001b[39;00m \u001b[39mimport\u001b[39;00m generate_binned_data\n\u001b[0;32m----> 9\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39;49mdevice\u001b[39m.\u001b[39;49mis_cuda_available():\n\u001b[1;32m     10\u001b[0m     device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'torch.device' has no attribute 'is_cuda_available'"
     ]
    }
   ],
   "source": [
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import numpy as np\n",
    "from generate_binned_data import generate_binned_data\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "spikes, speeds = generate_binned_data(data_path='sleep_data')\n",
    "spikes = np.array(spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c16ad71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neurons: 143\n",
      "neuron 0: (2912723,)\n",
      "neuron 1: (2912723,)\n",
      "neuron 2: (2912723,)\n",
      "neuron 3: (2912723,)\n",
      "neuron 4: (2912723,)\n",
      "neuron 5: (2912723,)\n",
      "neuron 6: (2912723,)\n",
      "neuron 7: (2912723,)\n",
      "neuron 8: (2912723,)\n",
      "neuron 9: (2912723,)\n",
      "...\n",
      "speeds: (2912725,)\n"
     ]
    }
   ],
   "source": [
    "print(f'neurons: {spikes.shape[0]}')\n",
    "for i in range(10):\n",
    "    print(f'neuron {i}: {spikes[i].shape}')\n",
    "print('...')\n",
    "print(f'speeds: {speeds.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd9ff606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct pytorch lightning data module\n",
    "class SpikeDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, spikes, speeds, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.spikes = torch.from_numpy(spikes)\n",
    "        self.speeds = torch.from_numpy(speeds)\n",
    "        self.batch_size = batch_size\n",
    "        self.train_seq_len = spikes.shape[0]\n",
    "        # self.window_size =  window_size  # note: window_size should equal receptive field size of 1d-CNN\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # split dataset (paw_power, spikes) into train, val, test\n",
    "        train_test_split_ind = self.train_seq_len//5*4\n",
    "        self.data_train = TensorDataset(self.spikes[0:train_test_split_ind], self.speeds[0:train_test_split_ind])\n",
    "        self.data_val = TensorDataset(self.spikes[train_test_split_ind:], self.speeds[train_test_split_ind:])\n",
    "        # self.data_test = TensorDataset(self.spikes[train_test_split_ind:], self.speeds[train_test_split_ind:])\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.data_train, batch_size=self.batch_size, shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.data_val, batch_size=self.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05ae1dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct pytorch lightning module of 3-layer basic 1-D CNN model\n",
    "class SpikeModel(pl.LightningModule):\n",
    "    def __init__(self, n_neurons):\n",
    "        super().__init__()\n",
    "        # Note: receptive field is currently 1 + 2*L = 7\n",
    "        self.conv1 = nn.Conv1d(n_neurons, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv1d(64, 16, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv3 = nn.Conv1d(16, 1, kernel_size=3, stride=1, padding=0)\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.dropout = nn.Dropout(0.2)\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z1 = self.relu(self.conv1(x))\n",
    "        # x = self.dropout(x)\n",
    "        z2 = self.relu(self.conv2(z1))\n",
    "        # x = self.dropout(x)\n",
    "        y_hat = self.relu(self.conv3(z2))\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6dc609e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = SpikeDataModule(spikes, speeds)\n",
    "spike_model = SpikeModel(n_neurons=spikes.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0524e0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3-layer basic 1-D CNN model\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "        \n",
    "#         # define convolutional layers\n",
    "#         self.conv1 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=0)\n",
    "#         self.conv2 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=0)\n",
    "#         self.conv3 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=0)\n",
    "\n",
    "#         # define pooling layer\n",
    "#         # self.pool = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "#         # define relu layer\n",
    "#         self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.relu(x)\n",
    "#         # x = self.pool(x)\n",
    "#         x = self.conv3(x)\n",
    "#         x = self.relu(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06819ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add in loading from above into the init function\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# construct pytorch dataset class\n",
    "# 1. get all spikes in a 1 second window\n",
    "# 2. get all power in a 1 second window\n",
    "class SpikeDataset(Dataset):\n",
    "    def __init__(self, ttl_times, spikes, front_left_paw_speed, front_right_paw_speed, window_size=10, step_size=1):\n",
    "        self.ttl_times = ttl_times\n",
    "        self.spikes = spikes\n",
    "        self.front_left_paw_speed = front_left_paw_speed\n",
    "        self.front_right_paw_speed = front_right_paw_speed\n",
    "        # note: window_size should equal receptive field size of 1d-CNN\n",
    "        self.window_size = window_size\n",
    "        self.step_size = step_size\n",
    "\n",
    "        # calculate power here\n",
    "\n",
    "        # toy data to move forward\n",
    "        self.paw_power = np.ones(100)\n",
    "        self.spikes = np.ones(100)\n",
    "    \n",
    "    def __len__(self):\n",
    "        # TODO: check this\n",
    "        return len(self.spikes) // self.window_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # for one 'subsequence', pull out binned spikes and power\n",
    "        spike_subsequence = self.spikes[idx*self.window_size:(idx+1)*self.window_size]\n",
    "        power_subsequence = self.paw_power[idx*self.window_size:(idx+1)*self.window_size]\n",
    "        return spike_subsequence, power_subsequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489c688d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8159f54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1dconv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
