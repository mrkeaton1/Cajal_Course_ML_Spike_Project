{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "effddfc8-1018-47c4-9b16-02a320425184",
   "metadata": {},
   "source": [
    "## Initial codebase for implementing 1D convolutional network on mouse wake+sleep spiking data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd242ff",
   "metadata": {},
   "source": [
    "## To-do:\n",
    "1. dataset\n",
    "2. dataloader\n",
    "3. 1d-conv\n",
    "4. Analysis: attributions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960a4f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchmetrics\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from preprocessing import generate_binned_data, obtain_binned_rhythm, obtain_binned_acceleration\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# rhythm = obtain_binned_rhythm(rhythm)\n",
    "# binned_speeds = obtain_rhythm_percentiles(speeds)\n",
    "\n",
    "spikes = np.load(os.path.join('sleep_data', 'spikes.npy'))\n",
    "rhythm = np.load(os.path.join('sleep_data', 'rhythm.npy'))\n",
    "acceleration = np.load(os.path.join('sleep_data', 'acceleration.npy'))\n",
    "behavior = np.load(os.path.join('sleep_data', 'behavior.npy'))\n",
    "\n",
    "binned_acceleration, spikes = obtain_binned_acceleration(behavior, acceleration, spikes, just_running=False)\n",
    "n_classes = 6\n",
    "\n",
    "# binned_acceleration, spikes = obtain_binned_acceleration(behavior, acceleration, spikes, just_running=True)\n",
    "# binned_acceleration = binned_acceleration - 2\n",
    "# n_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91eccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spikes, rhythm, acceleration, behavior = generate_binned_data(data_path='sleep_data')\n",
    "# spikes = np.array(spikes).transpose()\n",
    "\n",
    "# np.save(os.path.join('sleep_data', 'spikes.npy'), spikes)\n",
    "# np.save(os.path.join('sleep_data', 'rhythm.npy'), rhythm)\n",
    "# np.save(os.path.join('sleep_data', 'acceleration.npy'), acceleration)\n",
    "# np.save(os.path.join('sleep_data', 'behavior.npy'), behavior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3716f395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(acceleration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f393f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acceleration[400000:405000], color='orange')\n",
    "plt.title('Acceleration (difference of front paw speeds)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1c2547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for behavior\n",
    "# print(np.unique(behavior, return_counts=True))\n",
    "# test_behavior = behavior+1\n",
    "# classes, weights = np.unique(test_behavior, return_counts=True)\n",
    "# print(classes, weights)\n",
    "# behavior_encoding = torch.nn.functional.one_hot(torch.tensor(test_behavior), num_classes=3).numpy()\n",
    "# # classes, weights = np.unique(test_behavior[:,2], return_counts=True)\n",
    "# # print(classes, weights)\n",
    "# weights = torch.tensor([weights[i]/spikes.shape[0] for i in classes])\n",
    "# print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069dad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(rhythm[1010000:1020000])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c16ad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'behavior: {behavior.shape}')\n",
    "# print(f'neurons: {spikes.shape[0]}')\n",
    "# for i in range(10):\n",
    "#     print(f'neuron {i}: {spikes[i].shape}')\n",
    "# print('...')\n",
    "# print(f'speeds: {rhythm.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa51ad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsequence_length = 100\n",
    "# windowed_spikes = torch.from_numpy(spikes)\n",
    "# windowed_rhythm = torch.from_numpy(rhythm)\n",
    "# windowed_behavior = torch.from_numpy(behavior)\n",
    "# windowed_spikes = torch.stack([windowed_spikes[i:i+subsequence_length] for i in range(0, 10000-subsequence_length, subsequence_length)], dim=0)\n",
    "# windowed_speeds = torch.stack([windowed_rhythm[i:i+subsequence_length] for i in range(0, 10000-subsequence_length, subsequence_length)], dim=0)\n",
    "# windowed_behavior = torch.stack([windowed_behavior[i:i+subsequence_length] for i in range(0, 10000-subsequence_length, subsequence_length)], dim=0)\n",
    "# print(f'windowed spikes: {windowed_spikes.shape}')\n",
    "# print(f'windowed speeds: {windowed_speeds.shape}')\n",
    "# print(f'windowed behavior: {windowed_behavior.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20e05f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsequence_len = 100\n",
    "# train_seq_len = spikes.shape[0]\n",
    "# stacked_spikes = torch.from_numpy(spikes)\n",
    "# stacked_behavior = torch.from_numpy(behavior)\n",
    "# stacked_spikes = torch.stack([stacked_spikes[i:i+subsequence_len] for i in range(0, train_seq_len-2*subsequence_len, subsequence_len)], dim=0)\n",
    "# stacked_spikes = torch.transpose(stacked_spikes, 1, 2)\n",
    "# stacked_behavior = torch.stack([stacked_behavior[i:i+subsequence_len] for i in range(0, train_seq_len-2*subsequence_len, subsequence_len)], dim=0)\n",
    "# print(f'stacked spikes: {stacked_spikes.shape}; stacked behavior: {stacked_behavior.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9ff606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct pytorch lightning data module\n",
    "class SpikeDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, spikes, behavior, num_classes, batch_size=16, subsequence_length=1000):\n",
    "        super().__init__()\n",
    "        self.spikes = torch.from_numpy(spikes)\n",
    "        self.behavior = torch.from_numpy(behavior+1)\n",
    "        self.batch_size = batch_size\n",
    "        self.train_seq_len = spikes.shape[0]\n",
    "        self.subsequence_len =  subsequence_length  # Note: subsequence length is not necessarily the same as the receptive field size\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # break spikes into windows of size window_size\n",
    "        print(f'spikes: {self.spikes.shape}; behavior: {self.behavior.shape}')\n",
    "        self.spikes = torch.stack([self.spikes[i:i+self.subsequence_len] for i in range(0, self.train_seq_len-self.subsequence_len, self.subsequence_len)], dim=0)\n",
    "        self.spikes = torch.transpose(self.spikes, 1, 2).to(torch.float32)\n",
    "        self.behavior = torch.nn.functional.one_hot(self.behavior, num_classes=self.num_classes)\n",
    "        self.behavior = torch.stack([self.behavior[i:i+self.subsequence_len] for i in range(0, self.train_seq_len-self.subsequence_len, self.subsequence_len)], dim=0)\n",
    "        self.behavior = torch.transpose(self.behavior, 1, 2).to(torch.float32)\n",
    "        print(f'spikes: {self.spikes.shape}; behavior: {self.behavior.shape}')\n",
    "        \n",
    "        # TODO : testing; remove this\n",
    "        # self.spikes = torch.cat((self.spikes, self.behavior), dim=1)\n",
    "\n",
    "        # split dataset (behavior, spikes) into train, val, test\n",
    "        # train_test_split_ind = self.spikes.shape[0]//5*4\n",
    "        # train_val_split_ind = train_test_split_ind//5*4\n",
    "\n",
    "        # print(train_test_split_ind, train_val_split_ind)\n",
    "\n",
    "        first_train_split_ind = round(self.spikes.shape[0]*.4)\n",
    "        end_val_split_ind = round(self.spikes.shape[0]*.5)\n",
    "        end_test_split_ind = round(self.spikes.shape[0]*.6)\n",
    "\n",
    "        first_train_split_spikes = self.spikes[0:first_train_split_ind]\n",
    "        first_train_split_behavior = self.behavior[0:first_train_split_ind]\n",
    "        second_train_split_spikes = self.spikes[end_test_split_ind:]\n",
    "        second_train_split_behavior = self.behavior[end_test_split_ind:]\n",
    "        \n",
    "        self.data_train = TensorDataset(torch.cat((first_train_split_spikes, second_train_split_spikes), dim=0),\n",
    "                                        torch.cat((first_train_split_behavior, second_train_split_behavior), dim=0))\n",
    "        self.data_val = TensorDataset(self.spikes[first_train_split_ind:end_val_split_ind], self.behavior[first_train_split_ind:end_val_split_ind])\n",
    "        self.data_test = TensorDataset(self.spikes[end_val_split_ind:end_test_split_ind], self.behavior[end_val_split_ind:end_test_split_ind])\n",
    "        # self.data_train = TensorDataset(self.spikes[0:train_val_split_ind], self.behavior[0:train_val_split_ind])\n",
    "        # self.data_val = TensorDataset(self.spikes[train_val_split_ind:train_test_split_ind], self.behavior[train_val_split_ind:train_test_split_ind])\n",
    "        # self.data_test = TensorDataset(self.spikes[train_test_split_ind:], self.behavior[train_test_split_ind:])\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.data_train, batch_size=self.batch_size, shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.data_val, batch_size=self.batch_size, shuffle=False)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.data_test, batch_size=self.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ae1dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct pytorch lightning module of 3-layer basic 1-D CNN model\n",
    "class SpikeModel(pl.LightningModule):\n",
    "    def __init__(self, n_neurons, out_dim, weights, lr=1e-4, receptive_field=60):\n",
    "        super().__init__()\n",
    "        self.out_dim = out_dim\n",
    "        # Note: receptive field is currently 1 + 2*L = 7\n",
    "        self.conv1 = nn.Conv1d(n_neurons, 64, kernel_size=20, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv1d(64, 16, kernel_size=21, stride=1, padding=0)\n",
    "        self.conv3 = nn.Conv1d(16, out_dim, kernel_size=21, stride=1, padding=0)\n",
    "        self.receptive_field = receptive_field\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.loss = nn.CrossEntropyLoss(weight=weights, reduction='mean')\n",
    "        self.lr = lr\n",
    "        # self.train_accuracy = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=out_dim, multidim_average='samplewise')\n",
    "        # self.val_accuracy = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=out_dim, multidim_average='samplewise')\n",
    "        # self.test_accuracy = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=out_dim, multidim_average='samplewise')\n",
    "        # self.train_accuracy = torchmetrics.classification.MulticlassAccuracy(num_classes=out_dim, multidim_average='global')\n",
    "        # self.val_accuracy = torchmetrics.classification.MulticlassAccuracy(num_classes=out_dim, multidim_average='global')\n",
    "        # self.test_accuracy = torchmetrics.classification.MulticlassAccuracy(num_classes=out_dim, multidim_average='global')\n",
    "        self.epoch_train_accuracies = []\n",
    "        self.epoch_val_accuracies = []\n",
    "        self.epoch_test_accuracies = []\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def forward(self, x):\n",
    "        z1 = self.relu(self.conv1(x))\n",
    "        z1 = self.dropout(z1)\n",
    "        z2 = self.relu(self.conv2(z1))\n",
    "        z2 = self.dropout(z2)\n",
    "        y_hat = self.conv3(z2)\n",
    "        return y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # x = y.clone()\n",
    "\n",
    "        # Predict on LAST time step\n",
    "        y = y[:, :, self.receptive_field-1:]\n",
    "\n",
    "        # # Predict on MIDLE time step\n",
    "        # first_half = self.receptive_field//2\n",
    "        # second_half = self.receptive_field - first_half\n",
    "        # y = y[:, :, first_half:-second_half+1]\n",
    "\n",
    "        y_hat = self.forward(x)\n",
    "\n",
    "        if batch_idx == 0 and self.current_epoch % 10 == 0:\n",
    "            print(f'y_hat shape: {y_hat.shape}; y shape: {y.shape}')\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        # combine 0th and 2nd dimension of y_hat\n",
    "\n",
    "        y_flat = y.transpose(0, 1).flatten(1, 2).transpose(0, 1)\n",
    "        y_hat_flat = y_hat.transpose(0, 1).flatten(1, 2).transpose(0, 1)\n",
    "        y_flat = torch.argmax(y_flat, dim=1)\n",
    "        y_hat_flat = torch.argmax(y_hat_flat, dim=1)\n",
    "        # print(f'y_hat_flat shape: {y_hat_flat.shape}; y_flat shape: {y_flat.shape}')\n",
    "        step_accuracy = torch.sum(y_hat_flat == y_flat) / (y_flat.shape[0])\n",
    "        self.log('train_accuracy', step_accuracy)\n",
    "        self.epoch_train_accuracies.append(step_accuracy)\n",
    "\n",
    "\n",
    "        # self.train_accuracy(y_hat_flat, y_flat)\n",
    "        # self.train_accuracy(y_hat, y)\n",
    "        # self.log('train_acc_step', self.train_accuracy)            \n",
    "        if batch_idx == 0 and self.current_epoch % 50 == 0:\n",
    "\n",
    "            # print(f'y_hat_flat shape: {y_hat_flat.shape}; y_flat shape: {y_flat.shape}')\n",
    "            # print(f'y_flat: {y_flat[0].detach().cpu()}')\n",
    "            pred = torch.argmax(y_hat, dim=1)\n",
    "            # print(f'pred: {y_hat[0].detach().cpu().numpy().transpose()}')\n",
    "            y_class = torch.argmax(y, dim=1)\n",
    "            plt.figure()\n",
    "            sample_pred = pred[0].detach().cpu().numpy().transpose()\n",
    "            sample_y = y_class[0].detach().cpu().numpy().transpose()\n",
    "            print(f'prediction shape: {sample_pred.shape}')\n",
    "            plt.plot(sample_pred, label='prediction')\n",
    "            plt.plot(sample_y, label='ground truth')\n",
    "            plt.title('Training sample prediction')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(x[0].detach().cpu().numpy(), aspect='auto')\n",
    "            plt.title('Training sample input')\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Neuron')\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure()\n",
    "            raw_sample_pred = y_hat[0].detach().cpu().numpy().transpose()\n",
    "            if self.out_dim == 6:\n",
    "                plt.plot(raw_sample_pred[:,0], label='raw prediction (class 0 - still)')\n",
    "                plt.plot(raw_sample_pred[:,1], label='raw prediction (class 1 - other)')\n",
    "                plt.plot(raw_sample_pred[:,2], label='raw prediction (class 2 - running 1)')\n",
    "                plt.plot(raw_sample_pred[:,3], label='raw prediction (class 3 - running 2)')\n",
    "                plt.plot(raw_sample_pred[:,4], label='raw prediction (class 4 - running 3)')\n",
    "                plt.plot(raw_sample_pred[:,5], label='raw prediction (class 5 - running 4)')\n",
    "            elif self.out_dim == 4:\n",
    "                plt.plot(raw_sample_pred[:,0], label='raw prediction (class 0 - running 1)')\n",
    "                plt.plot(raw_sample_pred[:,1], label='raw prediction (class 1 - running 2)')\n",
    "                plt.plot(raw_sample_pred[:,2], label='raw prediction (class 2 - running 3)')\n",
    "                plt.plot(raw_sample_pred[:,3], label='raw prediction (class 3 - running 4)')\n",
    "            plt.title('Training prediction raw confidences')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # self.log('train_acc_epoch', self.train_accuracy)\n",
    "        self.log('train_acc_epoch', torch.mean(torch.tensor(self.epoch_train_accuracies)))\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # x = torch.Tensor([y.clone() for i in range(143)])\n",
    "        # x = y.clone()\n",
    "        \n",
    "        # Predict on LAST time step\n",
    "        y = y[:, :, self.receptive_field-1:]\n",
    "\n",
    "        # # Predict on MIDDLE time step\n",
    "        # first_half = self.receptive_field//2\n",
    "        # second_half = self.receptive_field - first_half\n",
    "        # y = y[:, :, first_half:-second_half+1]\n",
    "\n",
    "        # print(f'x shape: {x.shape}')\n",
    "        # print(f'y shape: {y.shape}')\n",
    "        y_hat = self.forward(x)\n",
    "        # print(f'y_hat shape: {y_hat.shape}; y shape: {y.shape}')\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log('val_loss', loss)\n",
    "        # self.val_accuracy(y_hat, y)\n",
    "        # self.log('val_acc_step', self.val_accuracy)\n",
    "\n",
    "        y_flat = y.transpose(0, 1).flatten(1, 2).transpose(0, 1)\n",
    "        y_hat_flat = y_hat.transpose(0, 1).flatten(1, 2).transpose(0, 1)\n",
    "        y_flat = torch.argmax(y_flat, dim=1)\n",
    "        y_hat_flat = torch.argmax(y_hat_flat, dim=1)\n",
    "        # print(f'y_hat_flat shape: {y_hat_flat.shape}; y_flat shape: {y_flat.shape}')\n",
    "        step_accuracy = torch.sum(y_hat_flat == y_flat) / (y_flat.shape[0])\n",
    "        self.log('val_accuracy', step_accuracy)\n",
    "        self.epoch_val_accuracies.append(step_accuracy)\n",
    "\n",
    "        if batch_idx == 0 and self.current_epoch % 100 == 0:\n",
    "\n",
    "            # print(f'y_hat_flat shape: {y_hat_flat.shape}; y_flat shape: {y_flat.shape}')\n",
    "            # print(f'y_flat: {y_flat[0].detach().cpu()}')\n",
    "            pred = torch.argmax(y_hat, dim=1)\n",
    "            # print(f'pred: {y_hat[0].detach().cpu().numpy().transpose()}')\n",
    "            y_class = torch.argmax(y, dim=1)\n",
    "            plt.figure()\n",
    "            sample_pred = pred[0].detach().cpu().numpy().transpose()\n",
    "            sample_y = y_class[0].detach().cpu().numpy().transpose()\n",
    "            print(f'prediction shape: {sample_pred.shape}')\n",
    "            plt.plot(sample_pred, label='prediction')\n",
    "            plt.plot(sample_y, label='ground truth')\n",
    "            plt.title('Validation sample prediction')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(x[0].detach().cpu().numpy(), aspect='auto')\n",
    "            plt.title('Validation sample input')\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Neuron')\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure()\n",
    "            raw_sample_pred = y_hat[0].detach().cpu().numpy().transpose()\n",
    "            if self.out_dim == 6:\n",
    "                plt.plot(raw_sample_pred[:,0], label='raw prediction (class 0 - still)')\n",
    "                plt.plot(raw_sample_pred[:,1], label='raw prediction (class 1 - other)')\n",
    "                plt.plot(raw_sample_pred[:,2], label='raw prediction (class 2 - running 1)')\n",
    "                plt.plot(raw_sample_pred[:,3], label='raw prediction (class 3 - running 2)')\n",
    "                plt.plot(raw_sample_pred[:,4], label='raw prediction (class 4 - running 3)')\n",
    "                plt.plot(raw_sample_pred[:,5], label='raw prediction (class 5 - running 4)')\n",
    "            elif self.out_dim == 4:\n",
    "                plt.plot(raw_sample_pred[:,0], label='raw prediction (class 0 - running 1)')\n",
    "                plt.plot(raw_sample_pred[:,1], label='raw prediction (class 1 - running 2)')\n",
    "                plt.plot(raw_sample_pred[:,2], label='raw prediction (class 2 - running 3)')\n",
    "                plt.plot(raw_sample_pred[:,3], label='raw prediction (class 3 - running 4)')\n",
    "            plt.title('Validation prediction raw confidences')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        return loss\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        # self.log('val_acc_epoch', self.val_accuracy)\n",
    "        self.log('val_acc_epoch', torch.mean(torch.tensor(self.epoch_val_accuracies)))\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # x = y.clone()\n",
    "        \n",
    "        # Predict on LAST time step\n",
    "        y = y[:, :, self.receptive_field-1:]\n",
    "\n",
    "        # # Predict on MIDDLE time step\n",
    "        # first_half = self.receptive_field//2\n",
    "        # second_half = self.receptive_field - first_half\n",
    "        # y = y[:, :, first_half:-second_half+1]\n",
    "\n",
    "        # print(f'x shape: {x.shape}')\n",
    "        # print(f'y shape: {y.shape}')\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log('test_loss', loss)\n",
    "\n",
    "\n",
    "        # self.test_accuracy(y_hat, y)\n",
    "        # self.log('test_acc_step', self.test_accuracy)\n",
    "        # pred = torch.argmax(y_hat, dim=1)\n",
    "        # step_accuracy = torch.sum(pred == y) / (y.shape[0] * y.shape[1])\n",
    "        # self.log('test_accuracy', step_accuracy)\n",
    "        y_flat = y.transpose(0, 1).flatten(1, 2).transpose(0, 1)\n",
    "        y_hat_flat = y_hat.transpose(0, 1).flatten(1, 2).transpose(0, 1)\n",
    "        y_flat = torch.argmax(y_flat, dim=1)\n",
    "        y_hat_flat = torch.argmax(y_hat_flat, dim=1)\n",
    "        # print(f'y_hat_flat shape: {y_hat_flat.shape}; y_flat shape: {y_flat.shape}')\n",
    "        step_accuracy = torch.sum(y_hat_flat == y_flat) / (y_flat.shape[0])\n",
    "        self.log('test_accuracy', step_accuracy)\n",
    "        self.epoch_test_accuracies.append(step_accuracy)\n",
    "\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            pred = torch.argmax(y_hat, dim=1)\n",
    "            y_class = torch.argmax(y, dim=1)\n",
    "            plt.figure()\n",
    "            sample_pred = pred[0].detach().cpu().numpy().transpose()\n",
    "            sample_y = y_class[0].detach().cpu().numpy().transpose()\n",
    "            print(f'prediction shape: {sample_pred.shape}')\n",
    "            plt.plot(sample_pred, label='prediction')\n",
    "            plt.plot(sample_y, label='ground truth')\n",
    "            plt.title('Test sample prediction')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(x[0].detach().cpu().numpy(), aspect='auto')\n",
    "            plt.title('Training sample input')\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Neuron')\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure()\n",
    "            raw_sample_pred = y_hat[0].detach().cpu().numpy().transpose()\n",
    "            if self.out_dim == 6:\n",
    "                plt.plot(raw_sample_pred[:,0], label='raw prediction (class 0 - still)')\n",
    "                plt.plot(raw_sample_pred[:,1], label='raw prediction (class 1 - other)')\n",
    "                plt.plot(raw_sample_pred[:,2], label='raw prediction (class 2 - running 1)')\n",
    "                plt.plot(raw_sample_pred[:,3], label='raw prediction (class 3 - running 2)')\n",
    "                plt.plot(raw_sample_pred[:,4], label='raw prediction (class 4 - running 3)')\n",
    "                plt.plot(raw_sample_pred[:,5], label='raw prediction (class 5 - running 4)')\n",
    "            elif self.out_dim == 4:\n",
    "                plt.plot(raw_sample_pred[:,0], label='raw prediction (class 0 - running 1)')\n",
    "                plt.plot(raw_sample_pred[:,1], label='raw prediction (class 1 - running 2)')\n",
    "                plt.plot(raw_sample_pred[:,2], label='raw prediction (class 2 - running 3)')\n",
    "                plt.plot(raw_sample_pred[:,3], label='raw prediction (class 3 - running 4)')\n",
    "            plt.title('Test prediction raw confidences')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        return loss\n",
    "    \n",
    "    def on_test_epoch_end(self):\n",
    "        # self.log('test_acc_epoch', self.test_accuracy)\n",
    "        self.log('test_acc_epoch', torch.mean(torch.tensor(self.epoch_test_accuracies)))\n",
    "    \n",
    "    def on_test_end(self):\n",
    "        print('Finished testing')\n",
    "        print(f'Loss: {self.trainer.callback_metrics[\"test_loss\"]}')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dc1e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for acceleration\n",
    "print(np.unique(binned_acceleration, return_counts=True))\n",
    "test_binned_acceleration = binned_acceleration+1\n",
    "classes, weights = np.unique(test_binned_acceleration, return_counts=True)\n",
    "print(classes, weights)\n",
    "binned_acceleration_encoding = torch.nn.functional.one_hot(torch.tensor(test_binned_acceleration), num_classes=6).numpy()\n",
    "# classes, weights = np.unique(test_behavior[:,2], return_counts=True)\n",
    "# print(classes, weights)\n",
    "weights = torch.tensor([weights[i]/spikes.shape[0] for i in classes])\n",
    "\n",
    "weights = 1/weights\n",
    "w_max = torch.max(weights)\n",
    "weights = weights/w_max\n",
    "print(f'weights: {weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc609e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger = pl.loggers.TensorBoardLogger('logs/', name='1D_CNN')\n",
    "# receptive_field = 60\n",
    "datamodule = SpikeDataModule(spikes, binned_acceleration, num_classes=n_classes)\n",
    "datamodule.setup()\n",
    "train_loader = datamodule.train_dataloader()\n",
    "val_loader = datamodule.val_dataloader()\n",
    "test_loader = datamodule.test_dataloader()\n",
    "spike_model = SpikeModel(n_neurons=spikes.shape[1], out_dim=n_classes, weights=weights)\n",
    "# spike_model = SpikeModel(n_neurons=3, out_dim=3, receptive_field=220)\n",
    "trainer = pl.Trainer(devices=1, max_epochs=2000)  # , logger=logger\n",
    "trainer.fit(spike_model, train_loader, val_loader)\n",
    "# trainer.fit(spike_model, datamodule)\n",
    "# trainer.validate(spike_model, val_loader)\n",
    "trainer.test(spike_model, test_loader)\n",
    "# trainer.test(spike_model, datamodule)\n",
    "# trainer.save_checkpoint(os.path.join('results', 'model.ckpt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1dconv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
